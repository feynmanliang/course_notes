\lecture{11}{2020-02-25}{}

\begin{definition}
  A finite or infinite sequence $(\xi)_{i \in \bN}$ in measurable space
  $(S, \cS)$ is \emph{exchangeable} if
  $(\xi_{k_i})_{i=1}^m \deq (\xi_i)_{i=1}^m$ for any $(k_i)_{i=1}^m$ distinct.

  $\xi$ is \emph{contractible} if the above holds for increasing $k_1 < \cdots < k_m$.
\end{definition}

\begin{definition}
  $(\xi_i)$ is \emph{conditionally iid} if
  $\Pr[\xi \in \cdot \mid \cF] \aseq \nu^\infty$
  for some $\sigma$-field $\cF$ and random probability measure $\nu$ on $S$.
\end{definition}
We can view $\nu$ as a probability kernel from the ambient probability space
$(\Omega, \cA)$ to $S$, or equivalently a random element of the space $\cM_1(S)$
of probability measures on $S$ equipped with $\sigma$-field generated by
projection maps $\pi_B : \mu \mapsto \mu B$ for $B \in \cS$.
Notice $\nu$ is almost surely $\cF$-measurable,
so we can take $\cF = \sigma(\nu)$. Taking expected values shows that $\xi$
is \emph{mixed iid} i.e.
\[
  \Pr[\xi \in \cdot]
  = \bE \nu^\infty
  = \int_{\cM_1(S)} m^\infty \Pr[\nu \in dm]
\]

\begin{definition}
  A measurable space $(S, \cS)$ is a \emph{Borel space} if
  there exists a measurable bijection $f : S \to B$ for some Borel subset
  $B \in \cB(\bR)$ such that $f^{-1}$ is measurable.
\end{definition}

\begin{theorem}
  For $(\xi)$ an infinite sequence of random elements in
  measurable Borel space $S$,
  contractible = exchangeable = conditionally iid.
\end{theorem}

\begin{note}{Borel is essential}
  $S$ Borel is essential, Blackwell has a counterexample.
\end{note}

\begin{proof}
  Suffices to show contractible implies conditionally iid, since
  the other implications are obvious.

  Let $\cI_\xi = \xi^{-1} \cI$ where $\cI$ denotes the shift-invariant
  $\sigma$-field in $(S, \cS)^\infty$.
  The conditional distribution $\nu = \Pr[\xi_1 \in \cdot \mid \cI_\xi]$
  exists since $S$ is Borel (hence regular conditional distributions exist).

  Fix $I \in \cI$ and bounded measurable functions $\{f_i\}_{i=1}^m$ on $S$.
  Since shift invariance means $\{\xi \in I\} = \{\theta_k \xi \in I\}$
  for all $k$,
  by contractibility, extended mean ergodic theorem, and dominated convergence
  theorem, as $n \to \infty$
  \begin{align*}
    \bE \ind_I(\xi) \prod_{k \leq m} f_k(\xi_k)
    &= n^{-m} \sum_{j_1,\ldots,j_m \leq n} \bE \ind_I(\xi) \prod_{k \leq m} f_k(\xi_{kn + j_k}) \\
    &= \bE \ind_I(\xi) \prod_{k \leq m} n^{-1} \sum_{j \leq n} f_k(\xi_{kn + j_k}) \\
    &\to \bE \ind_I(\xi) \prod_{k \leq m} \nu f_k
  \end{align*}
  The first equality reindexes $k n + j_k \in [kn+1,(k+1)n]$ using
  contractibility and then averages over all $n^m$ choices of
  $(j_k)_{k=1}^m \in n^m$. The second equality simply rearranges sum of
  products into product of sums, which look like Cesaro sums except they
  start from $kn$ rather than $1$. Nevertheless, for fixed $k \in [m]$
  the sums
  \[
    n^{-1} \sum_{j \leq n} f_k(\xi_{k n + j_k}) \to_{L^p(\Pr)} \bE[ f_k(\xi_1) \mid \cI_\xi] = \nu f_k
  \]
  for any $p$ by the extended mean ergodic theorem, so in particular
  convergence in probability holds. Since it is bounded, by dominated
  convergence we may move the limit inside the expectation.

  But since there are no $n$s on the initial and final expression, we have
  in fact
  \[
    \bE \ind_I(\xi) \prod_{k \leq m} f_k(\xi_k)
    = \bE \ind_I(\xi) \prod_{k \leq m} \nu f_k
  \]

  The functions $(s_i)_1^m \mapsto \prod_{k \leq m} f_k(\xi_k)$ form a
  $\pi$-system, so by a monotone-class argument and the definition
  of conditional probabilities
  \[
    \Pr[\xi \in B \mid \cI_\xi] \aseq \nu^\infty B
  \]
  for all $B \in \cS^\infty$. This is the statement of conditionally iid
  with $\cF = \cI_\xi$.
\end{proof}

\begin{proposition}[Conditional independence, Doob]
  \label{prop:cond-indep-doob}
  For $\sigma$-fields $\cF$, $\cG$, and $\cH$, $\cF \perp_\cG \cH$ iff
  \[
    \Pr[H \mid \cF, \cG] \aseq \Pr[H \mid \cG]
  \]
  for all $H \in \cH$.
\end{proposition}

\begin{lemma}[Contraction and independence]
  If random elements $(\xi, \eta) \deq (\xi, \zeta)$
  and $\sigma(\eta) \subset \sigma(\zeta)$ (at least as much information
  in $\zeta$ as there is in $\eta$) then
  $\xi \perp_\eta \zeta$ ($\zeta$ is built from $\eta$ plus
  something additional which is conditionally independent given $\eta$).
\end{lemma}

\begin{proof}
  Fix measurable $B$ in range of $\xi$, define
  $\mu_1 = \Pr[\xi \in B \mid \eta]$
  and $\mu_2 = \Pr[\xi \in B \mid \zeta]$.

  (Useful facts about martingales: if $(\cF_n)$ is a filtration and $Z$ is a
  random variable, then $X_n = \bE[Z \mid \cF_n]$ is a martingale. Also,
  $L^2$ martingales have orthogonal increments.)
  Then $(\mu_1, \mu_2)$ is a bounded martingale with $\mu_1 \deq \mu_2$
  (so in particular $\bE \mu_2^2 = \bE \mu_1^2$),
  hence $\bE(\mu_2 - \mu_1)^2 = \bE \mu_2^2 - \bE \mu_1^2 = 0$ which implies
  $\mu_1 \aseq \mu_2$
\end{proof}

\begin{proof}[Second proof of Theorem contractible=exchangeable=conditionally iid]
  If $\xi$ is contractible, then
  \[
    (\xi_m, \theta_m \xi) \deq (\xi_k, \theta_m \xi) \deq (\xi_k, \theta_n \xi)
    \qquad k \leq m \leq n
  \]
  Let $\cT_\xi = \cap_n \sigma(\theta_n \xi)$ be the tail $\sigma$-field and
  fix $B \in \cS$. By the previous lemma and reverse martingale convergence,
  as $n \to \infty$
  \[
    \Pr[\xi_m \in B \mid \theta_m \xi]
    = \Pr[\xi_k \in B \mid \theta_m \xi]
    = \Pr[\xi_k \in B \mid \theta_n \xi]
    \asto \Pr[\xi_k \in B \mid \cT_\xi]
  \]
  where we used the lemma to assert that conditioning on less
  information $\theta_n \xi$ compared to $\theta_m \xi$ ($n > m$)
  doesn't change things, and as $n$ varies we have a reverse martingale.

  Since the two sides dont have $n$ appearing we in fact have
  \[
    \Pr[\xi_m \in B \mid \theta_m \xi]
    \aseq \Pr[\xi_m \in B \mid \cT_\xi]
    \aseq \Pr[\xi_1 \in B \mid \cT_\xi]
  \]
  Here, the first relation yields $\xi_m \perp_{\cT_\xi} \theta_m \xi$ for all
  $m \in \bN$, so iterating gives $(\xi_i)_i$ are conditionally independent
  given $\cT_\xi$.  The second relation shows the conditional distributoins
  agree almost surely, so together we have that shown conditionally iid with
  $\cF= \cT_\xi$ and $\nu=\Pr[\xi_1 \in \cdot \mid \cT_\xi]$.
\end{proof}

\begin{definition}
  A contractible/exchangeable sequence $\xi$ is \emph{extreme} if
  its distirbution $\mu$ cannot be expressed as a nontrivial mixture
  $p \mu_1 + (1-p) \mu_2$ of exchangeable/contratable distributions.

  We use $\cF \aseq \cG$ ($\sigma$-fields agree almost surely)
  to mean that the $\Pr$-completions agree.
\end{definition}

\begin{proposition}[Uniqueness and extremality]
  For $\xi$ an infinite exchangeable sequence in a Borel space $(S, \cS)$
  such that $\Pr[\xi \in \cdot \mid \cF] \aseq \nu^\infty$ for some
  $\sigma$-field $\cF$ and random probability measure $\nu$ on $S$,
  \begin{enumerate}
    \item $\nu$ is a.s. unique, $\xi$-measurable, and given by
      limiting empirical probability distribution
      \[
        n^{-1} \sum_{k \leq n} \ind_B(\xi_k) \asto \nu B\qquad B \in \cS
      \]
    \item $\cF \perp_\nu \xi$ and $\cF \subset \sigma(|xi)$ implies
      $\cF \aseq \sigma(\nu)$
    \item $\cL(\xi) = \int m^\infty \mu(dm)$
      (the law of $\xi$ is a mixture of infinite products)
      iff $\mu = \cL(\nu)$.
    \item $\cL(\xi)$ is extreme iff $\nu$ is a.s. non-random.
  \end{enumerate}
\end{proposition}

As a result of uniqueness, we will refer to the random $\nu$ as the
\emph{directing random measure} of $\xi$ and say $\xi$ is directed by $\nu$.

\begin{proof}
  (1) Fix measurable $f \geq 0$ on $S$. By disintegration theorem (??,
  taking $\nu = \nu^\infty, \eta = \nu f$)
  and SLLN
  \[
    \Pr\left\{
    n^{-1} \sum_{k \leq n}} f(\xi_k) \to \nu f
    \right\}
    = \bE \nu^\infty\left\{
      x; n^{-1} \sum_{k \leq n} f(x_k) \to \nu f
    \right\}
    = 1
  \]
  This proves convergence and a.s. uniqueness of $\nu$ follows by a monotone
  class argument with a countable class of nonnegative functions that
  generate $\cS$ (because we are dealing with a Borel space).

  (2) is clear from
  \cref{prop:cond-indep-doob} and disintegration corollary ???? 

  (3) Let $\tilde{\nu}$ be a random probability measure with distribution
  $\mu$ on $\cM_1(S)$. By extension lemma ??? we can construct a random
  $\eta = (\eta_j)$ on $S$ satisfying 
  $\Pr[\nu \in \cdot \mid \tilde{\nu}] \aseq \tilde{\nu}^\infty$. Then
  \[
    \Pr \circ \eta^{-1} = \bE \tilde{\nu}^\infty = \int m^\infty \mu(dm)
  \]
  and comparing with definition of conditionally iid we see
  $\nu \deq \tilde{\nu}$ implies $\xi \deq \eta$.

  Conversely, if $\xi \deq \eta$ then applying (1) to both $\xi$ and $\eta$
  shows $\nu f \deq \tilde{\nu} f$ for all measurable $f \geq 0$ on $S$,
  hence $\tilde{\nu} \deq \nu$ again by a monotone class argument.

  (4) Use (3) and the fact that a probability measure on
  $\cM_1(S)$ is extreme iff it is degenerate (concentrated at a single
  point).
\end{proof}
